<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, user-scalable=no">
	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

	<title>Voice Wave</title>


	<style>

		* {
			margin: 0;
			padding: 0;
		}

		html {
			background: #000;
		}

		html, body {
			height: 100%;
		}

		body {
			display: flex;
		}

		main {
			display: flex;
			flex-flow: column;
			max-width: 400px;
			width: 100%;
			height: 100%;
			margin: auto;
			background: #fff;
		}

		[flex] {
			flex: 1
		}

		canvas {
			display: block;
			width: 100%;
		}

		h1 {
			margin: auto;
			font-weight: 200;
			text-align: right;
			width: 100%;
			padding: 16px;
		}

	</style>
</head>
<body>

<main>
	<div flex style="display: flex">
		<h1 id="text"></h1>
	</div>
	<canvas id="canvas"></canvas>
</main>


<script>


let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");


let t = 1;
let c = 10;
let L = 300;
let a = 5;

let offset = 4;


document.onclick = document.ontouchstart = function(e) {
	document.onclick = document.ontouchstart = null;

	window.SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
	window.AudioContext = window.webkitAudioContext || window.AudioContext;

	if (SpeechRecognition) {
		let recognition = new SpeechRecognition();
		recognition.continuous = true;
		recognition.interimResults = true;
		recognition.lang = 'en-US';

		recognition.onresult = function(e) {
			document.getElementById("text").innerText = e.results[e.resultIndex][0].transcript;

		};

		recognition.start();
	}




	let audioContext = new AudioContext();

	let analyser_node = audioContext.createAnalyser();
	analyser_node.smoothingTimeConstant = 0;
	analyser_node.fftSize = 2048;


	let array_freq_domain = new Uint8Array(2048);

	navigator.getUserMedia({audio: true}, (stream) => {
			let microphone_stream = audioContext.createMediaStreamSource(stream);
			microphone_stream.connect(analyser_node);
		},
		function(e) {
			alert('Error capturing audio.');
		}
	);


	function draw() {
		requestAnimationFrame(draw);


		analyser_node.getByteFrequencyData(array_freq_domain);
		let smoothing = 0.8;
		let v = array_freq_domain[5];
		v = Math.round(v / 128 * 7 / 10) * 10;
		a = (a * smoothing) + (v * (1 - smoothing));
		a = Math.max(5, a);


		ctx.clearRect(0, 0, canvas.width, canvas.height);

		ctx.fillStyle = "rgba(200,200,0,.6)";
		ctx.strokeStyle = "#000";
		ctx.strokeWidth = "2px";

		ctx.beginPath();
		ctx.lineTo(-1, canvas.height);
		ctx.lineTo(-1, 80);

		for (let x = 0; x < 300; x++) {
			let y = a * Math.sin(Math.PI * 2 / L * (x - c * t));
			ctx.lineTo(x, y + 80);
		}

		ctx.lineTo(canvas.width + 1, canvas.height);
		ctx.closePath();

		ctx.fill();
		// ctx.stroke();


		ctx.fillStyle = "rgba(200,200,0,.2)";

		ctx.beginPath();
		ctx.lineTo(-1, canvas.height);
		ctx.lineTo(-1, 80);

		for (let x = 0; x < 300; x++) {
			let y = (a * 2) * Math.sin(Math.PI * 2 / L * (x - c * t + 150));
			ctx.lineTo(x, y + 80);
		}

		ctx.lineTo(canvas.width + 1, canvas.height);
		ctx.closePath();

		ctx.fill();


		ctx.fillStyle = "rgba(200,200,0,.4)";


		ctx.beginPath();
		ctx.lineTo(-1, canvas.height);
		ctx.lineTo(-1, 80);

		for (let x = 0; x < 300; x++) {
			let y = (a * 1.5) * Math.sin(Math.PI * 2 / L * (x - c * t + 100));
			ctx.lineTo(x, y + 60);
		}

		ctx.lineTo(canvas.width + 1, canvas.height);
		ctx.closePath();

		ctx.fill();


		// ctx.stroke();

		// t -= (offset/10);

		t -= 1;
		a *= 0.95;
		a = Math.max(3, a);

		// offset *= 0.99;
		// offset = Math.max(10, offset);

		// console.log(c);

	}

	draw();

}


</script>
</body>
</html>